{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNjQYLjfvj4quTz0w6NZ7UI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oMXnW-rgXklB"},"outputs":[],"source":["#!/usr/bin/env python\n","\"\"\" Downloads FaceForensics public data release\n","Example usage:\n","    # source-to-target\n","    python download.py -d \\<'compressed' or 'raw'> \\<output folder>\n","    # self-reenactment\n","    python download.py -d \\<'selfreenactment_compressed' or 'selfreenactment_raw'> \\<output folder>\n","    # cropped self-reenactment images\n","    python download.py -d selfreenactment_images' \\<output folder>\n","    # only original videos\n","    python download.py -d original_videos \\<output filename>\n","\"\"\"\n","# -*- coding: utf-8 -*-\n","import argparse\n","import os\n","import urllib\n","import urllib.request\n","import tempfile\n","from os.path import join\n","\n","\n","SERVER_URL = 'http://kaldir.vc.in.tum.de/FaceForensics/'\n","TOS_URL = SERVER_URL + 'webpage/FaceForensics_TOS.pdf'\n","BASE_URL = SERVER_URL + 'v1_cargo/'\n","ORIGINAL_VIDEOS_URL = BASE_URL + 'original_videos.tar.gz'\n","RELEASE_DATASET_SIZE = {'raw': '~3.5TB',\n","                        'compressed': '~130GB',\n","                        'images': '~135GB'}\n","DATASET_TYPES = [\"raw\", \"compressed\", \"selfreenactment_raw\",\n","                 \"selfreenactment_compressed\", \"original_videos\",\n","                 \"selfreenactment_images\", \"source_to_target_images\"]\n","NUM_SAMPLES=5\n","\n","\n","def get_filelist(filelist_url):\n","    lines = urllib.request.urlopen(filelist_url)\n","    video_filenames = []\n","    for line in lines:\n","        line = line.decode('utf-8')\n","        video_filename = line.rstrip('\\n')\n","        video_filenames.append(video_filename)\n","    return video_filenames\n","\n","\n","def download_files(filenames, base_url, output_path, sample_only=False):\n","    os.makedirs(output_path, exist_ok=True)\n","    num_filenames=len(filenames) if not sample_only else NUM_SAMPLES\n","    for i, filename in enumerate(filenames):\n","        if i % 10 == 0:\n","            print(\"{}/{}\".format(i, num_filenames))\n","        download_file(base_url + filename, join(output_path, filename))\n","        if sample_only and i != 0 and i % (NUM_SAMPLES - 1) == 0:\n","            break\n","    print(\"{}/{}\".format(num_filenames, num_filenames))\n","\n","\n","def download_file(url, out_file):\n","    out_dir = os.path.dirname(out_file)\n","    if not os.path.isfile(out_file):\n","        fh, out_file_tmp = tempfile.mkstemp(dir=out_dir)\n","        f = os.fdopen(fh, 'w')\n","        f.close()\n","        urllib.request.urlretrieve(url, out_file_tmp)\n","        os.rename(out_file_tmp, out_file)\n","    else:\n","        print('WARNING: skipping download of existing file ' + out_file)\n","\n","\n","def main():\n","    parser = argparse.ArgumentParser(\n","        description='Downloads FaceForensics public data release.')\n","    parser.add_argument('output_path', help='directory in which to download')\n","    parser.add_argument('-d', '--dataset_type', default='compressed',\n","                        help='Enter which dataset you want to download: '\\\n","                             '\"raw\", \"compressed\", \"selfreenactment_raw\", ' \\\n","                             '\"selfreenactment_compressed\", ' \\\n","                             '\"original_videos\" ' \\\n","                             '\"source_to_target_images\" or ' \\\n","                             '\"selfreenactment_images\".')\n","    parser.add_argument('--not_altered', action='store_true',\n","        help=\"don't download face2face altered videos\")\n","    parser.add_argument('--not_original', action='store_true',\n","        help=\"don't download original videos\")\n","    parser.add_argument('--not_mask', action='store_true',\n","        help=\"don't download face2face mask videos\")\n","    parser.add_argument('--not_test', action='store_true',\n","        help=\"don't download videos of the test set\")\n","    parser.add_argument('--not_train', action='store_true',\n","        help=\"don't download videos of the training set\")\n","    parser.add_argument('--not_val', action='store_true',\n","        help=\"don't download videos of the validation set\")\n","    parser.add_argument('--sample_only', action='store_true',\n","        help='activate this, if you only want to download 5 files per '\n","             'subfolder')\n","    args = parser.parse_args()\n","\n","    # Check for dataset type\n","    if args.dataset_type not in DATASET_TYPES:\n","        raise Exception('Wrong dataset type. Please consult \"-h\" for possible'\n","                        'options.')\n","\n","    # TOS\n","    print('By pressing any key to continue you confirm that you have agreed '\\\n","          'to the FaceForensics terms of use as described at:')\n","    print(TOS_URL)\n","    print('***')\n","    print('Press any key to continue, or CTRL-C to exit.')\n","    key = input('')\n","\n","    # Check which videos to download\n","    downloaded_video_types = []\n","    if not args.not_altered: downloaded_video_types.append('altered')\n","    if not args.not_original: downloaded_video_types.append('original')\n","    if not 'images' in args.dataset_type:\n","        if not args.not_mask: downloaded_video_types.append('mask')\n","\n","    # Check which folders to download\n","    downloaded_folders = []\n","    if not args.not_test: downloaded_folders.append('test')\n","    if not args.not_train: downloaded_folders.append('train')\n","    if not args.not_val: downloaded_folders.append('val')\n","\n","    # Check for dataset type\n","    if 'selfreenactment' in args.dataset_type:\n","        dataset = 'selfreenactment'\n","        dataset_type = args.dataset_type.replace('selfreenactment_', '')\n","    else:\n","        dataset = 'source_to_target'\n","        dataset_type = args.dataset_type.replace('source_to_target_', '')\n","\n","    # Warning\n","    if not args.dataset_type == 'original_videos':\n","        dataset_filesize = RELEASE_DATASET_SIZE[dataset_type]\n","        print('***')\n","        if not args.sample_only:\n","            print('WARNING: You are downloading the FaceForensics dataset {} of'\n","                  ' size {}'.format(args.dataset_type, dataset_filesize))\n","        print(\n","            'Note that existing scan directories will be skipped. Delete ' \\\n","            'partially downloaded directories to re-download.')\n","        print('***')\n","        print('Press any key to continue, or CTRL-C to exit.')\n","        key = input('')\n","\n","    # Download\n","    print('\\nDownloading dataset: {}'.format(args.dataset_type))\n","    if args.dataset_type == 'original_videos':\n","        print('Please be patient, this may take a while (~2gb)')\n","        download_file(ORIGINAL_VIDEOS_URL,\n","                      out_file=join(args.output_path,\n","                                    'faceforensics_original_videos.tar.gz'))\n","    else:\n","        for folder in downloaded_folders:\n","            if 'images' in args.dataset_type:\n","                filelist_folder = 'images_' + folder\n","            else:\n","                filelist_folder = folder\n","            filelist_url = BASE_URL + '{}/filelists/{}.txt'.format(dataset,\n","                                                                filelist_folder)\n","            filenames = get_filelist(filelist_url)\n","            print('\\nDownloading {}'.format(folder))\n","            for video_type in downloaded_video_types:\n","                output_path = join(args.output_path,\n","                                   'FaceForensics_{}'.format(args.dataset_type),\n","                                   folder, video_type)\n","                print('{}/{} > {}'.format(folder, video_type, output_path))\n","                base_url = BASE_URL + '{}/{}/{}/{}/'.format(dataset,\n","                                                            dataset_type,\n","                                                            folder,video_type)\n","                download_files(filenames, base_url, output_path=output_path,\n","                               sample_only=args.sample_only)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}